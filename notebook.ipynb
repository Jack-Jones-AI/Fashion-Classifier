{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00000-6340369e-d65b-4e45-85b5-41d0bc84b83c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c52f9753",
    "execution_start": 1622450470921,
    "execution_millis": 4277,
    "deepnote_cell_type": "code"
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 0 T-shirt/top \n",
    "- 1 Trouser \n",
    "- 2 Pullover \n",
    "- 3 Dress \n",
    "- 4 Coat \n",
    "- 5 Sandal \n",
    "- 6 Shirt \n",
    "- 7 Sneaker \n",
    "- 8 Bag \n",
    "- 9 Ankle boot\n",
    "\n",
    "Dataset:\n"
   ],
   "metadata": {
    "tags": [],
    "cell_id": "00001-04969011-c05d-4c90-b134-93eca84c2f7c",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_train = pd.read_csv(\"./data/fashion-mnist_train.csv\")\n",
    "df_test = pd.read_csv(\"./data/fashion-mnist_test.csv\")"
   ],
   "metadata": {
    "tags": [],
    "cell_id": "00001-1f2d6e1a-a9a6-441b-9229-027866600a38",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "12e28aa6",
    "execution_start": 1622450525884,
    "execution_millis": 5560,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "df_train.describe()"
   ],
   "metadata": {
    "tags": [],
    "cell_id": "00002-640684d6-7ae5-4008-b696-a18f5b90dfdc",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "849ce5a8",
    "execution_start": 1622450537140,
    "execution_millis": 5325,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              label        pixel1        pixel2        pixel3        pixel4  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean       4.500000      0.000900      0.006150      0.035333      0.101933   \n",
       "std        2.872305      0.094689      0.271011      1.222324      2.452871   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        4.500000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        7.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        9.000000     16.000000     36.000000    226.000000    164.000000   \n",
       "\n",
       "             pixel5        pixel6        pixel7        pixel8        pixel9  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean       0.247967      0.411467      0.805767      2.198283      5.682000   \n",
       "std        4.306912      5.836188      8.215169     14.093378     23.819481   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      227.000000    230.000000    224.000000    255.000000    254.000000   \n",
       "\n",
       "       ...      pixel775      pixel776      pixel777      pixel778  \\\n",
       "count  ...  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean   ...     34.625400     23.300683     16.588267     17.869433   \n",
       "std    ...     57.545242     48.854427     41.979611     43.966032   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...     58.000000      9.000000      0.000000      0.000000   \n",
       "max    ...    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "           pixel779      pixel780      pixel781      pixel782      pixel783  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean      22.814817     17.911483      8.520633      2.753300      0.855517   \n",
       "std       51.830477     45.149388     29.614859     17.397652      9.356960   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "          pixel784  \n",
       "count  60000.00000  \n",
       "mean       0.07025  \n",
       "std        2.12587  \n",
       "min        0.00000  \n",
       "25%        0.00000  \n",
       "50%        0.00000  \n",
       "75%        0.00000  \n",
       "max      170.00000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n      <th>pixel784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>...</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.500000</td>\n      <td>0.000900</td>\n      <td>0.006150</td>\n      <td>0.035333</td>\n      <td>0.101933</td>\n      <td>0.247967</td>\n      <td>0.411467</td>\n      <td>0.805767</td>\n      <td>2.198283</td>\n      <td>5.682000</td>\n      <td>...</td>\n      <td>34.625400</td>\n      <td>23.300683</td>\n      <td>16.588267</td>\n      <td>17.869433</td>\n      <td>22.814817</td>\n      <td>17.911483</td>\n      <td>8.520633</td>\n      <td>2.753300</td>\n      <td>0.855517</td>\n      <td>0.07025</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.872305</td>\n      <td>0.094689</td>\n      <td>0.271011</td>\n      <td>1.222324</td>\n      <td>2.452871</td>\n      <td>4.306912</td>\n      <td>5.836188</td>\n      <td>8.215169</td>\n      <td>14.093378</td>\n      <td>23.819481</td>\n      <td>...</td>\n      <td>57.545242</td>\n      <td>48.854427</td>\n      <td>41.979611</td>\n      <td>43.966032</td>\n      <td>51.830477</td>\n      <td>45.149388</td>\n      <td>29.614859</td>\n      <td>17.397652</td>\n      <td>9.356960</td>\n      <td>2.12587</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>58.000000</td>\n      <td>9.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.000000</td>\n      <td>16.000000</td>\n      <td>36.000000</td>\n      <td>226.000000</td>\n      <td>164.000000</td>\n      <td>227.000000</td>\n      <td>230.000000</td>\n      <td>224.000000</td>\n      <td>255.000000</td>\n      <td>254.000000</td>\n      <td>...</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>170.00000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 785 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "tags": [],
    "cell_id": "00006-9c7b1d73-2159-404d-84cb-101b3b78baa4",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "tags": [],
    "cell_id": "00005-64d59d2f-801e-4ccd-a276-cc92192a3fa1",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "913b0d52",
    "execution_start": 1622450791118,
    "execution_millis": 5,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "class FashionDataset(Dataset):\n",
    "    \"\"\"User defined class to build a datset using Pytorch class Dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, data, transform = None):\n",
    "        \"\"\"Method to initilaize variables.\"\"\" \n",
    "        self.fashion_MNIST = list(data.values)\n",
    "        self.transform = transform\n",
    "        \n",
    "        label = []\n",
    "        image = []\n",
    "        \n",
    "        for i in self.fashion_MNIST:\n",
    "             # first column is of labels.\n",
    "            label.append(i[0])\n",
    "            image.append(i[1:])\n",
    "        self.labels = np.asarray(label)\n",
    "        # Dimension of Images = 28 * 28 * 1. where height = width = 28 and color_channels = 1.\n",
    "        self.images = np.asarray(image).reshape(-1, 28, 28, 1).astype('float32')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels[index]\n",
    "        image = self.images[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ],
   "metadata": {
    "tags": [],
    "cell_id": "00006-3d30779a-2c9c-4aa4-95cc-42f7f3ea71bd",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d7920655",
    "execution_start": 1622450842944,
    "execution_millis": 12,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "# Transform data into Tensor that has a range from 0 to 1\n",
    "train_set = FashionDataset(df_train, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_set = FashionDataset(df_test, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=100)\n",
    "test_loader = DataLoader(train_set, batch_size=100)"
   ],
   "metadata": {
    "tags": [],
    "cell_id": "00007-841c7a92-b591-4061-bdef-200337f82cdc",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "690a197",
    "execution_start": 1622450861015,
    "execution_millis": 722,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-280e55a23adc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Transform data into Tensor that has a range from 0 to 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFashionDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFashionDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-3245cfbe3b05>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, transform)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Dimension of Images = 28 * 28 * 1. where height = width = 28 and color_channels = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/machine_learning/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": [
    "def output_label(label):\n",
    "    output_mapping = {\n",
    "                 0: \"T-shirt/Top\",\n",
    "                 1: \"Trouser\",\n",
    "                 2: \"Pullover\",\n",
    "                 3: \"Dress\",\n",
    "                 4: \"Coat\", \n",
    "                 5: \"Sandal\", \n",
    "                 6: \"Shirt\",\n",
    "                 7: \"Sneaker\",\n",
    "                 8: \"Bag\",\n",
    "                 9: \"Ankle Boot\"\n",
    "                 }\n",
    "    input = (label.item() if type(label) == torch.Tensor else label)\n",
    "    return output_mapping[input]"
   ],
   "metadata": {
    "tags": [],
    "cell_id": "00008-18279cce-2fe3-4d71-b590-a47ed4059939",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "aad6908b",
    "execution_start": 1622450902014,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "a = next(iter(train_loader))\n",
    "a[0].size()"
   ],
   "metadata": {
    "tags": [],
    "cell_id": "00009-b7c17c71-e049-413d-8651-986ee46fb9c7",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e4cb1f32",
    "execution_start": 1622450924104,
    "execution_millis": 69,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "image, label = next(iter(train_set))\n",
    "plt.imshow(image.squeeze(), cmap=\"gray\")"
   ],
   "metadata": {
    "tags": [],
    "cell_id": "00010-68baa7e5-5c98-4587-a1f9-affbb3aa5e4d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c1bafebf",
    "execution_start": 1622450958534,
    "execution_millis": 151,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "label"
   ],
   "metadata": {
    "tags": [],
    "cell_id": "00011-6867d663-af91-44d3-99fd-01b78e80856c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "82ef483e",
    "execution_start": 1622450963396,
    "execution_millis": 10,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "demo_loader = torch.utils.data.DataLoader(train_set, batch_size=10)\n",
    "\n",
    "batch = next(iter(demo_loader))\n",
    "images, labels = batch\n",
    "print(type(images), type(labels))\n",
    "print(images.shape, labels.shape)"
   ],
   "metadata": {
    "tags": [],
    "cell_id": "00012-17e69bef-ac51-4dfe-899d-9a0b0562543c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b15471f9",
    "execution_start": 1622450998135,
    "execution_millis": 13,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "grid = torchvision.utils.make_grid(images, nrow=10)\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "print(\"labels: \", end=\" \")\n",
    "for i, label in enumerate(labels):\n",
    "    print(output_label(label), end=\", \")"
   ],
   "metadata": {
    "tags": [],
    "cell_id": "00013-cd05ef29-f5a8-4166-b202-ff67d2f047f9",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b51bffde",
    "execution_start": 1622451006537,
    "execution_millis": 208,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "class FashionCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(FashionCNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)\n",
    "        self.drop = nn.Dropout2d(0.25)\n",
    "        self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
    "        self.fc3 = nn.Linear(in_features=120, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        return out"
   ],
   "metadata": {
    "tags": [],
    "cell_id": "00014-c54d93af-636e-4a3c-8e75-828f26caca9a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "cfbe27cf",
    "execution_start": 1622451121610,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = FashionCNN()\n",
    "model.to(device)\n",
    "\n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)"
   ],
   "metadata": {
    "tags": [],
    "cell_id": "00015-032b0889-de44-4d57-9fe1-eff67decd3f3",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ede39eff",
    "execution_start": 1622451167242,
    "execution_millis": 8,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "num_epochs = 5\n",
    "count = 0\n",
    "# Lists for visualization of loss and accuracy \n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "# Lists for knowing classwise accuracy\n",
    "predictions_list = []\n",
    "labels_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        # Transfering images and labels to GPU if available\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "        train = Variable(images.view(100, 1, 28, 28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward pass \n",
    "        outputs = model(train)\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Initializing a gradient as 0 so there is no mixing of gradient among the batches\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Propagating the error backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimizing the parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "        count += 1\n",
    "    \n",
    "    # Testing the model\n",
    "    \n",
    "        if not (count % 50):    # It's same as \"if count % 50 == 0\"\n",
    "            total = 0\n",
    "            correct = 0\n",
    "        \n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                labels_list.append(labels)\n",
    "            \n",
    "                test = Variable(images.view(100, 1, 28, 28))\n",
    "            \n",
    "                outputs = model(test)\n",
    "            \n",
    "                predictions = torch.max(outputs, 1)[1].to(device)\n",
    "                predictions_list.append(predictions)\n",
    "                correct += (predictions == labels).sum()\n",
    "            \n",
    "                total += len(labels)\n",
    "            \n",
    "            accuracy = correct * 100 / total\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "        \n",
    "        if not (count % 500):\n",
    "            print(\"Iteration: {}, Loss: {}, Accuracy: {}%\".format(count, loss.data, accuracy))"
   ],
   "metadata": {
    "tags": [],
    "cell_id": "00016-56cbdac7-f919-4906-8b71-975155d03c4b",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "1a223526",
    "execution_start": 1622451200443,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "tags": [],
    "cell_id": "00017-20d9e4dc-9cf9-4b75-9314-b50114b18be8",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "8361a578-3a4c-4e97-9270-039f46e98718",
  "deepnote_execution_queue": [
   {
    "cellId": "00016-56cbdac7-f919-4906-8b71-975155d03c4b",
    "sessionId": "5945d224-7fb8-4685-ac08-f427aa4e5c85",
    "msgId": "fe4dfdd0-3c1f-4532-93bb-9f0e167f04aa"
   }
  ],
  "kernelspec": {
   "name": "python388jvsc74a57bd02d78e359ff02d0c79ca305c8815f63c63e3b9beac7f2ccf04f89f33a94ce9080",
   "display_name": "Python 3.8.8 64-bit ('machine_learning': conda)"
  }
 }
}